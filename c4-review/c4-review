#!/usr/bin/env python3

import sys
import subprocess
import csv
import urllib.request
from io import StringIO
import json
import argparse
import dateutil.parser
import datetime
import re
import os.path

BASE = 0.6 # Base for Sybil protection. Was once 0.9 but 0.6 since Oct 2022

parser = argparse.ArgumentParser(prog="c4-review", formatter_class=argparse.RawTextHelpFormatter,
                                  description="Takes judges review spreadsheet and provides stats. Estimates payout if you provide a handle")
subp = parser.add_subparsers(dest="command") # dest="command" means that we see which command was parsed

payout = subp.add_parser("payouts", description="Find out the fraction of total pot or payouts")
payout.add_argument('csv_file', type=str)
payout.add_argument('pot_size', type=int, nargs='?')
payout.add_argument('-w', '--handle', type=str, nargs='?')
payout.add_argument('-b', '--base', type=str,nargs=1)

findings = subp.add_parser("findings", description="Summary of findings, including duplicate counts")
findings.add_argument('csv_file', type=str)
findings.add_argument('pot_size', type=int, nargs='?')
findings.add_argument('-b', '--base', type=str,nargs=1)

#
# Functions
#
def get_records(csvr):
  rs = []
  headers = ["reportId", "duplicateOf", "score", "risk", "handle", "title", "issueId", "issueUrl", "gh_Risk", "gh_isOpen", "gh_isDuplicate", "gh_isInvalid"]
  for row in csvr:
    r = {}
    for i in range(0, len(headers)):
      r[headers[i]] = row[i]
    rs.append(r)
  return rs

def get_records_from_file(f):
  with open(f) as csv_file:
    csvr = csv.reader(csv_file)
    return get_records(csvr)


def ppUSD(n):
  return '${:0,.2f}'.format(round(n, 2))

def ppMonth(epochTime):
  dt = datetime.datetime.fromtimestamp(epochTime)
  return dt.strftime("%B %Y")

def ppTime(epochTime):
  dt = datetime.datetime.fromtimestamp(epochTime)
  return dt.isoformat();

def isHigh(s):
  return len(re.findall("^H-", s)) > 0

def isMedium(s):
  return len(re.findall("^M-", s)) > 0


def getIssueSummary(ns):
  rs = get_records_from_file(ns.csv_file)
  h = {}
  for r in rs:
    id=r["reportId"]
    if len(re.findall("^[HM]-", id)) >0: # HM sers!
      if not id in h:
        h[id] = { "id": id, "dups": 0, "leadFinding": "unknown", "handles": [] }
      if r["duplicateOf"] == "":
        h[id]["leadFinding"] = r["handle"]
        h[id]["githubIssueId"] = r["issueId"]
      if not r["handle"] in h[id]["handles"]:
        h[id]["dups"] += 1
        h[id]["handles"].append(r["handle"])
  ## Calculate shares
  totalShares = 0.0
  for key in h:
    baseShares = 10.0 if isHigh(key) else 3.0
    dups = h[key]["dups"]
    h[key]["sharesForIssue"] = baseShares * BASE**(dups - 1)
    h[key]["sharesPerDup"] = h[key]["sharesForIssue"] / dups
    totalShares += h[key]["sharesForIssue"]

  # A pass to calculate fractions and payouts
  for key in h:
    h[key]["fractionPerDup"] = h[key]["sharesPerDup"] / totalShares
    if ns.pot_size != None:
      h[key]["payoutPerDup"] = h[key]["fractionPerDup"] * ns.pot_size
  return { "totalShares": totalShares, "issueMap": h }

def payout(ns):
  issueSummary = getIssueSummary(ns)
  h = issueSummary["issueMap"]
  # Summarise results for each handle
  ws = {}
  for id in h:
    for w in h[id]["handles"]:
      if not w in ws:
        ws[w] = { "handle": w, "findings": [], "fraction": 0.0 }
        if ns.pot_size != None:
          ws[w]["payout"] = 0.0
      rec = { "id": id, "dups": h[id]["dups"], "fractionPerDup": h[id]["fractionPerDup"] }
      if ns.pot_size != None:
        rec["payoutPerDup"] = ppUSD(h[id]["payoutPerDup"])
      ws[w]["findings"].append(rec)
      ws[w]["fraction"] += h[id]["fractionPerDup"]
      if ns.pot_size != None:
        ws[w]["payout"] += h[id]["payoutPerDup"]
  if ns.pot_size != None:
    for w in ws:
      ws[w]["payout"] = ppUSD(ws[w]["payout"])
      ws[w]["findings"].sort(key=lambda r: r["id"])

  wardenSummaries = [ws[w] for w in ws if (lambda w: ns.handle == None or w == ns.handle)(w)]
  wardenSummaries.sort(key=lambda r: -r["fraction"])

  rs = { "totalShares": issueSummary["totalShares"], "payouts": wardenSummaries }
  return rs

def findings(ns):
  issueSummary = getIssueSummary(ns)
  h = issueSummary["issueMap"]
  for id in h:
    if "payoutPerDup" in h[id]:
      h[id]["payoutPerDup"] = ppUSD(h[id]["payoutPerDup"])
  rs = [h[k] for k in h]
  rs.sort(key=lambda r: r["id"])
  return { "totalShares": issueSummary["totalShares"], "findings": rs }

ns = parser.parse_args(sys.argv[1:])

#
# Set the base if the -b, --base flag is provided
# or the csv_file if it is provided
#
def set_base(base, csv_file):
  global BASE
  if base != None:
    BASE = float(base[0])
  elif csv_file != None:
    # Now check file name
    prefix = re.findall("^[0-9][0-9][0-9][0-9]-[0-9][0-9]", os.path.basename(csv_file))
    if len(prefix) > 0:
      s = prefix[0]
      if s <= "2022-10":
        BASE=0.9

set_base(ns.base, ns.csv_file)

if ns.command == "payouts":
  result=payout(ns)
elif ns.command == "findings":
  result=findings(ns)
else:
  parser.parse_args(["--help"])

result["note"] = ("This tool only calculates shares for Highs and Mediums and will overestimate " +
                    "a little. It does not take into account QA reports.")

## Prints the records as valid JSON
print(json.dumps(result, indent=2))